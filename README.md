# 2022 Spring AC221-Final-Project Group 10
## How do Face Datasets Inform Attractiveness?
The overarching goal of our project is to analyze the compounding effect bias can have when that bias originates within the original dataset and then is exacerbated while developing the algorithm. As we have seen in our discussions in class, historical biases and representation biases can seep into the dataset and can then result in more favorable model outcomes for one group over another. We believe such biases exist in the CelebA dataset, especially within the training set, and as a result the models based on this dataset produce biased results. The CelebA dataset, also known as the CelebFaces Attributes Dataset, is a dataset of over 200,000 images for over 10,000 celebrities [1]. Each image is evaluated across 40 different attributes, many of these attributes are basic human features, such as hair color, existence of facial hair, or if the celebrity is wearing glasses. Other attributes are more subjective, such as the key attribute we will be focusing on, attractiveness. Each image is evaluated on attractiveness and given a value of -1 or 1. 
We believe that attributes, like attractiveness, are impossible to evaluate quantitatively, and illustrate how a dataset exhibits inherent bias. Certain groups of people such as younger individuals will be given an unfair advantage over older people and considered to be more attractive, even if that is not necessarily true. Thus, while building a model to determine attractiveness, the bias from the dataset will influence and bias our results as well. We hope that through our analysis, we can illustrate the importance of detecting dataset biases early on, and to either adjust for them when building models to ensure that the results are not biased or to restart the data collection process to reduce the influence of such biases.
